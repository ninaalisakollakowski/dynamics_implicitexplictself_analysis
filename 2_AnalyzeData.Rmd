---
title: "2_AnalyzeData"
author: "Nina-Alisa Kollakowski"
date: "`r Sys.Date()`"
output: html_document
---

## Initializing
```{r}
set.seed(350)
library(dplyr)
library(mice)
library(psych)
library(lavaan)

nImputations <- 500
```

## Defining measures

```{r}
##defining measures
implicitSelfMeasures <- c("spatialContingency_looking", 
                          "spatialContingency_legs", 
                          "temporalContingency_looking",
                          "temporalContingency_left",
                          "temporalContingency_right",
                          "reaching_arm",
                          "reaching_head",
                          "sensoryAttenuation_pos",
                          "sensoryAttenuation_neg")
explicitSelfMeasures <- c("mirrorSelfRecognition", 
                          "videoSelfRecognition", 
                          "bodySizeDoor_errorFree",
                          "bodySizeToys_errorFree", 
                          "bodyObstacle_errorFree", 
                          "selfUnderstanding_passed", 
                          "placing_correct")
continuousVariables <- c("spatialContingency_looking", 
                         "spatialContingency_legs", 
                         "temporalContingency_looking",
                         "temporalContingency_left",
                         "temporalContingency_right",
                         "reaching_arm",
                         "reaching_head",
                         "sensoryAttenuation_pos",
                         "sensoryAttenuation_neg",
                         "bodySizeToys_errorFree", 
                         "bodyObstacle_errorFree", 
                         "selfUnderstanding_passed", 
                         "placing_correct")
dichotomousVariables <- c("mirrorSelfRecognition", 
                          "videoSelfRecognition", 
                          "bodySizeDoor_errorFree")
demographicVariables_numeric <- c("education_mother",
                                  "education_father",
                                  "Age_Mother",
                                  "Age_Father",
                                  "age_T1_spatialContingency",
                                  "age_T1_temporalContingency",
                                  "age_T2_reaching",
                                  "age_sensoryAttenuation",
                                  "age_T3")
demographicVariables_factor <- c("Marital_Status_num",
                                 "Siblings_num",
                                 "Primary_Language_Child_num",
                                 "Primary_Caretaker_num",
                                 "sex")
```

##load dataset
```{r}
load("joinedSelfData.RData")
currentData <- selfData
rm(selfData)
nObservations = nrow(currentData)
```

## Define correct variable types
For imputation to choose correct method for imputation, dichotomous variables need to be defined as factor
```{r}
currentData[dichotomousVariables] <- lapply(currentData[dichotomousVariables], factor)
```

## Compare demographic information of children who contributed more or less data
```{r prepare}
#add information on how much data was contributed by each child
#T1_only: only contributed to T1 (therefore other age variables empty)
#T1_and_T2: contributed data to T1 and T2 (therefore T3 age variable empty)
#allTimepoints: contributed data to all time points
demographics <- currentData %>% 
  mutate(time = ifelse(is.na(age_T2_reaching) & is.na(age_T3), "T1_only", 
                       ifelse(!is.na(age_T2_reaching) & is.na(age_T3), "T1_and_T2", 
                              "allTimepoints")))

#summarise numeric demographic variables
demographics %>%
  group_by(time) %>%
  summarise(across(all_of(demographicVariables_numeric),  ~ mean(.x, na.rm = TRUE)),
            n = n())
```

```{r maternal education}
# = the higher the number, the more education in school and tertiary education) -> no significant differences
model.edu_mother <- lm(education_mother  ~ time, data = demographics)
summary(model.edu_mother)
```

```{r paternal education}
#(= the higher the number, the more education in school and tertiary education) -> no significant differences
model.edu_father <- lm(education_father  ~ time, data = demographics)
summary(model.edu_father)
```

```{r maternal age}
#age of mother at T1 -> no significant differences
model.age_mother <- lm(Age_Mother  ~ time, data = demographics)
summary(model.age_mother)
```

```{r paternal age}
#age of father at T1 -> no significant differences
model.age_father <- lm(Age_Father  ~ time, data = demographics)
summary(model.age_father)
```

```{r child age}
#age of child at T1 (as only this information is available for all children) -> no significant differences
model.age_child <- lm(age_T1_spatialContingency  ~ time, data = demographics)
summary(model.age_child)
```

```{r marital status}
# (0 = unmarried, 1 = married, 2 = divorced, 3 = widowed) -> not significant
demo_marital_status <- table(demographics$Marital_Status_num, demographics$time)
fisher.test(demo_marital_status) #using fisher's test as Chi-Square claims that approximation might be incorrect
```

```{r siblings}
# (0 = no siblings, 1 = at least one sibling) -> not significant
demo_siblings <- table(demographics$Siblings_num, demographics$time)
fisher.test(demo_siblings)
```

```{r language}
#primary language of child (1 = german, 0 = other) -> not significant
demo_language <- table(demographics$Primary_Language_Child_num, demographics$time)
fisher.test(demo_language)
```

```{r caretaker}
#primary caretaker at T1 (0 = mother, 1 = father, 2 = both) -> not significant
demo_caretaker <- table(demographics$Primary_Caretaker_num, demographics$time)
fisher.test(demo_caretaker)
```

```{r sex}
#sex of child (m = male, w = female) -> significant
demo_sex <- table(demographics$sex, demographics$time)
fisher.test(demo_sex)
#more male children contributed data only to T1 (9/1), or to T1 and T2 (7/2) than contributed data to all time points (49/51)
```

##check for systematic missingness in data
conduct Little's MCAR test to confirm that data is missing at random
```{r}
#exclude demographic data here because with them in the model correlation of variables is too high to perform the test
naniar::mcar_test(currentData %>%
                    select(-all_of(demographicVariables_numeric),
                           -all_of(demographicVariables_factor))) # p = .051 -> not the case
```


##scale dataset
without scaling CFA was giving the warnings that "some observed variances are (at least) a factor 1000 times larger than others; use varTable(fit) to investigate"
```{r}
currentData_scaled <- currentData %>%
  select(-id) %>% #exclude id (throws errors otherwise)
  mutate_at(continuousVariables, 
            ~(scale(.) %>% as.vector))
```


## impute Data
if data is defined as factor or numerical, mice package will automatically select the correct imputation method for each variable type:
(extract from mice help: By default, the method uses pmm, predictive mean matching (numeric data) logreg, logistic regression imputation (binary data, factor with 2 levels) polyreg, polytomous regression imputation for unordered categorical data (factor > 2 levels) polr, proportional odds model for (ordered, > 2 levels).)
```{r}
#impute 500 different datasets and set seed to make reproducible
#try imputation without demographic data to see if EFA works

currentData_scaled_woDemo <- currentData_scaled %>%
  select(-all_of(demographicVariables_factor),
         -all_of(demographicVariables_numeric))

imputedData <- mice(currentData_scaled_woDemo, #currentData_scaled, 
                    m = nImputations,
                    print = FALSE, 
                    seed = 350)

save(imputedData, file = "imputedData.Rdata")
```

## load imputed dataset
```{r}
load("imputedData.Rdata")
```

## compute correlation matrix for implicit/explicit measures for each imputed dataset
use psych::mixedCor for this
```{r echo=FALSE}
#initialize lists of correlations and standard deviations
correlationData_implicit <- vector("list", nImputations)
correlationData_explicit <- vector("list", nImputations)
standardDeviations_implicit <- vector("list", nImputations)
standardDeviations_explicit <- vector("list", nImputations)

for (i in 1:nImputations){
  #extract current imputed dataset
  curDataset <- complete(imputedData, action = i)
  
  #define factor variables back to numeric as otherwise correlation function does not work
  curDataset[dichotomousVariables] <- lapply(curDataset[dichotomousVariables], as.numeric)
  
  #compute standard deviations of measures as a matrix as needed for covariance matrix
  standardDeviations_implicit[[i]] <- diag(sapply(curDataset %>%
                                                    select(all_of(implicitSelfMeasures)),
                                                  sd)) #implicit
  
  standardDeviations_explicit[[i]] <- diag(sapply(curDataset %>%
                                                    select(all_of(explicitSelfMeasures)), 
                                                  sd)) #explicit
  
  #calculate correlations of implicit measures    
  correlationData_implicit[[i]] <- mixedCor(curDataset %>%
                                              select(all_of(implicitSelfMeasures)),
                                            c = intersect(implicitSelfMeasures, continuousVariables),
                                            d = intersect(implicitSelfMeasures, dichotomousVariables))$rho 
  
  #calculate correlations of explicit measures
  correlationData_explicit[[i]] <- mixedCor(curDataset %>%
                                              select(all_of(explicitSelfMeasures)),
                                            c = intersect(explicitSelfMeasures, continuousVariables),
                                            d = intersect(explicitSelfMeasures, dichotomousVariables))$rho 
}
rm(curDataset)
```

## create covariance matrix from each correlation matrix
```{r}
#initialize lists of covariances
covarianceData_implicit <- vector("list", nImputations)
covarianceData_explicit <- vector("list", nImputations)

for (i in 1:nImputations){
  covarianceData_implicit[[i]] <- standardDeviations_implicit[[i]] %*% correlationData_implicit[[i]] %*% standardDeviations_implicit[[i]]
  
  covarianceData_explicit[[i]] <- standardDeviations_explicit[[i]] %*% correlationData_explicit[[i]] %*% standardDeviations_explicit[[i]]
}
```

## create average matrices for implicit/explicit measures
```{r}
covariance_implicit <- apply(simplify2array(covarianceData_implicit), c(1,2), mean)
rownames(covariance_implicit) <- implicitSelfMeasures
colnames(covariance_implicit) <- implicitSelfMeasures

covariance_explicit <- apply(simplify2array(covarianceData_explicit), c(1,2), mean)
rownames(covariance_explicit) <- explicitSelfMeasures
colnames(covariance_explicit) <- explicitSelfMeasures

correlation_implicit <- apply(simplify2array(correlationData_implicit), c(1,2), mean)
rownames(correlation_implicit) <- implicitSelfMeasures
colnames(correlation_implicit) <- implicitSelfMeasures

correlation_explicit <- apply(simplify2array(correlationData_explicit), c(1,2), mean)
rownames(correlation_explicit) <- explicitSelfMeasures
colnames(correlation_explicit) <- explicitSelfMeasures

```


## compute CFA of implicit/explicit measures
MLR estimator -> not possible because computing it with covariance matrix only
evaluate fit using X2-test, RMSEA, SRMR, CFI
good fit if 3/4 indicators suggest good fit
X2 = non-significant
RMSEA < .08
SRMR <.11
CFI >.95
```{r CFA implicit}
implicitCFA.model <- "implicit =~ spatialContingency_looking + spatialContingency_legs + temporalContingency_looking + temporalContingency_left + temporalContingency_right + reaching_arm + reaching_head + sensoryAttenuation_pos + sensoryAttenuation_neg"

implicitCFA <- cfa(implicitCFA.model, 
                   sample.cov = covariance_implicit, 
                   sample.nobs = nObservations,
                   estimator = "ML")

summary(implicitCFA)
fitMeasures(implicitCFA, fit.measures = c("rmsea", "srmr", "cfi"))
```
significant X2-test (p = 0.000) -> bad
RMSEA > .08 (0.144) -> bad
SRMR > .11 (0.117) -> bad
CFI < .95 (0.322) -> bad
all indicators show bad fit of CFA for implicit measures -> perform EFA

```{r CFA explicit}
explicitCFA.model <- 'explicit =~ mirrorSelfRecognition + 
                                  videoSelfRecognition + 
                                  bodySizeDoor_errorFree + 
                                  bodySizeToys_errorFree +
                                  bodyObstacle_errorFree + 
                                  selfUnderstanding_passed +
                                  placing_correct'
explicitCFA <- cfa(explicitCFA.model, sample.cov = covariance_explicit, sample.nobs = nObservations) 
summary(explicitCFA)
fitMeasures(explicitCFA, fit.measures = c("rmsea", "srmr", "cfi"))
```
significant X2-test (p = 0.004) -> bad
RMSEA > .08 (0.104) -> bad
SRMR < .11 (0.079) -> good
CFI < .95 (0.639) -> bad
3/4 indicators show bad fit of CFA for explicit measures -> perform EFA

##perform EFA for implicit measures
1) Bartlett's test to check if correlation matrix different from identity matrix (needs to be significant)
```{r Bartlett implicit}
cortest.bartlett(correlation_implicit, n = nObservations)
```
test is significant -> proceed
2) KMO >=.5, otherwise exclude variables with smallest KMO until criterion is reached
```{r KMO implicit 1}
KMO(correlation_implicit)

#define correlation matrix for later analysis
cur_correlation_implicit <- correlation_implicit
```

KMO = 0.46, exclude temporalContingency_left (0.41)

```{r KMO implicit 2}
#update correlation matrix without excluded variable
cur_correlation_implicit <- cur_correlation_implicit[!rownames(cur_correlation_implicit) == "temporalContingency_left",
                                              !colnames(cur_correlation_implicit) == "temporalContingency_left"]
#list excluded variables
excludedVariables_implicit_KMO <- list("temporalContingency_left")

#run KMO again
KMO(cur_correlation_implicit)
```

KMO = 0.51
however, when proceeding from here, parallel analysis suggests 4 factors and EFA produces Heywood cases
therefore now excluding variable with smallest KMO until all variables have KMO >= 0.5
first, exclude reaching_head (0.43)

```{r KMO implicit 3}
#update correlation matrix without excluded variable
cur_correlation_implicit <- cur_correlation_implicit[!rownames(cur_correlation_implicit) == "reaching_head",
                                              !colnames(cur_correlation_implicit) == "reaching_head"]

#list excluded variables
excludedVariables_implicit_KMO <- append(excludedVariables_implicit_KMO, "reaching_head")

#run KMO again
KMO(cur_correlation_implicit)
```

overall KMO = 0.55, but still variables < 0.5
exclude sensoryAttenuation_neg (0.42)

```{r KMO implicit 4}
#update correlation matrix without excluded variable
cur_correlation_implicit <- cur_correlation_implicit[!rownames(cur_correlation_implicit) == "sensoryAttenuation_neg",
                                              !colnames(cur_correlation_implicit) == "sensoryAttenuation_neg"]

#list excluded variables
excludedVariables_implicit_KMO <- append(excludedVariables_implicit_KMO, "sensoryAttenuation_neg")

#run KMO again
KMO(cur_correlation_implicit)
```

overall KMO = 0.59 & all variables > 0.5 -> proceed

3) parallel analysis with reduced correlation matrix to decide number of factors

```{r parallel analysis implicit}
fa.parallel(cur_correlation_implicit, n.obs = nObservations, n.iter = 1000, fm = "ml", fa = "fa")
```
parallel analysis suggests 2 factors

4) run EFA with principal axis factoring with oblique (direct oblimin) rotation
```{r EFA implicit}
#run EFA with 2 factors as suggested by parallel analysis
efa.implicit <- fa(cur_correlation_implicit, nfactors = 2, n.obs = nObservations, 
                   rotate = 'oblimin', fm = 'pa', max.iter = 1000)

#print results: cut-off of .4 as only loadings with >=.4 will be assigned to this factor
print.psych(efa.implicit, cut = .4, digits=3, sort=TRUE)

```

5) assign variables to factors with loadings of >=.4
```{r assign variables to implicit factors}
#exclude variables that don't load on any factor with loading of >=.4
excludedVariables_implicit <- append(excludedVariables_implicit_KMO, c("temporalContingency_looking",
                                                                   "sensoryAttenuation_pos",
                                                                   "temporalContingency_right"))

#extract factor loading from EFA
relevantFactorLoadings_implicit <- efa.implicit$loadings

#replace loadings < 0.4 with 0 for correct calculation of factor scores
relevantFactorLoadings_implicit[abs(relevantFactorLoadings_implicit) < 0.4] <- 0
```

6) calculate factor scores
```{r implicit factor scores}
#initialize lists for factor scores and all excluded variables
factorScores_implicit <- vector("list", nImputations)
otherVariables_implicit <- vector("list", nImputations)

#calculate factor scores and scores for excluded variables for each imputed dataset
for (i in 1:nImputations){
  curDataset <- complete(imputedData, action = i)
  
  factorScore_buffer <- curDataset %>%
    select(all_of(setdiff(implicitSelfMeasures, excludedVariables_implicit_KMO))) %>%
    factor.scores(x = ., relevantFactorLoadings_implicit)
  
  factorScores_implicit[[i]] <- factorScore_buffer$scores
  
  otherVariables_implicit[[i]] <- data.matrix(curDataset %>%
                                                select(all_of(simplify2array(excludedVariables_implicit))))
}
rm(factorScore_buffer)
rm(curDataset)

#create average factor scores and excluded variable scores for all datasets
factorScores_implicit_avg <- apply(simplify2array(factorScores_implicit), c(1,2), mean)
otherVariables_implicit_avg <- apply(simplify2array(otherVariables_implicit), c(1,2), mean)

#combine factor scores and scores for excluded variables into dataframe for implicit self
implicitSelf <- cbind(as.data.frame(factorScores_implicit_avg), as.data.frame(otherVariables_implicit_avg))
implicitSelf <- implicitSelf %>%
  rename(implicitFactor1 = PA1,
         implicitFactor2 = PA2) %>%
  mutate(id = 1:nObservations)
```


## perform EFA for explicit measures
1) Bartlett's test to check if correlation matrix different from identity matrix (needs to be significant)
```{r Bartlett explicit}
cortest.bartlett(correlation_explicit, n = nObservations)
```
test is significant -> proceed
2) KMO >.5, otherwise exclude variables with smallest KMO until criterion is reached
```{r KMO explicit 1}
KMO(correlation_explicit)
cur_correlation_explicit <- correlation_explicit
```
KMO = 0.52, 
however, when proceeding from here, parallel analysis suggests 4 factors and EFA produces Heywood cases
therefore now excluding variable with smallest KMO until all variables have KMO >= 0.5
first, exclude bodyObstacle_errorFree (0.34)

```{r KMO explicit 2}
#update correlation matrix without excluded variable
cur_correlation_explicit <- cur_correlation_explicit[!rownames(cur_correlation_explicit) == "bodyObstacle_errorFree",
                                              !colnames(cur_correlation_explicit) == "bodyObstacle_errorFree"]

#list excluded variables
excludedVariables_explicit_KMO <- list("bodyObstacle_errorFree")

#run KMO again
KMO(correlation_explicit1)
```

KMO = 0.54, but still one variable <.5 
excluding bodySizeToys_errorFree (0.36)

```{r KMO explicit 3}
#update correlation matrix without excluded variable
cur_correlation_explicit <- cur_correlation_explicit[!rownames(cur_correlation_explicit) == "bodySizeToys_errorFree",
                                              !colnames(cur_correlation_explicit) == "bodySizeToys_errorFree"]

#list excluded variables
excludedVariables_explicit_KMO <- append(excludedVariables_explicit_KMO, "bodySizeToys_errorFree")

#run KMO again
KMO(cur_correlation_explicit)
```
KMO = 0.65 & all variables >0.5 -> proceed

3) parallel analysis with reduced correlation matrix to decide number of factors

```{r parallel analysis explicit}
fa.parallel(cur_correlation_explicit, n.obs = nObservations, n.iter = 1000, fm = "ml", fa = "fa")
```
parallel analysis 2 factors

4) run EFA with principal axis factoring with oblique (direct oblimin) rotation
```{r EFA explicit}
#run EFA with 2 factors as suggested by parallel analysis
efa.explicit <- fa(cur_correlation_explicit, nfactors = 2, n.obs = nObservations, 
                   rotate = 'oblimin', fm = 'pa', max.iter = 1000)

#print results: cut-off of .4 as only loadings with >=.4 will be assigned to this factor
print.psych(efa.explicit, cut = .4, digits=3, sort=TRUE) 

```

5) assign variables to factors with loadings of >=.4
```{r assign to explicit factors}
#extract factor loading from EFA
relevantFactorLoadings_explicit <- efa.explicit$loadings

#replace loadings < 0.4 with 0 for correct calculation of factor scores
relevantFactorLoadings_explicit[abs(relevantFactorLoadings_explicit) < 0.4] <- 0
```

6) calculate factor scores
```{r explicit factor scores}
#initialize lists for factor scores and all excluded variables
factorScores_explicit <- vector("list", nImputations)
otherVariables_explicit <- vector("list", nImputations)

#calculate factor scores and scores for excluded variables for each imputed dataset
for (i in 1:nImputations){
  curDataset <- complete(imputedData, action = i)
  
  #define factor variables back to numeric to be able to compute means
  curDataset[dichotomousVariables] <- lapply(curDataset[dichotomousVariables], as.numeric)
  
  factorScore_buffer <- curDataset %>%
    select(all_of(setdiff(explicitSelfMeasures, excludedVariables_explicit_KMO))) %>%
    factor.scores(x = ., relevantFactorLoadings_explicit)
  
  factorScores_explicit[[i]] <- factorScore_buffer$scores
  
  otherVariables_explicit[[i]] <- data.matrix(curDataset %>%
                                                select(all_of(simplify2array(excludedVariables_explicit_KMO))))
}
rm(factorScore_buffer)
rm(curDataset)

#create average factor scores and excluded variable scores for all datasets
factorScores_explicit_avg <- apply(simplify2array(factorScores_explicit), c(1,2), mean)
otherVariables_explicit_avg <- apply(simplify2array(otherVariables_explicit), c(1,2), mean)

#combine factor scores and scores for excluded variables into dataframe for explicit self
explicitSelf <- cbind(as.data.frame(factorScores_explicit_avg), as.data.frame(otherVariables_explicit_avg))
explicitSelf <- explicitSelf %>%
  rename(explicitFactor1 = PA1,
         explicitFactor2 = PA2) %>%
  mutate(id = 1:nObservations)
```


## linear regressions of implicit -> explicit self TODO
run regressions of each explicit factor/variable with all implicit factors/variables as predictors
```{r prepare dataframe}
#merge implicit and explicit dataset
selfData <- merge(implicitSelf, explicitSelf, by = "id")
```

```{r explicit factor 1}
explicitFactor1.model <- lm(explicitFactor1 ~ implicitFactor1 + 
                              implicitFactor2 +
                              temporalContingency_left +
                              reaching_head +
                              sensoryAttenuation_neg + 
                              temporalContingency_looking +
                              sensoryAttenuation_pos +
                              temporalContingency_right, 
                            data = selfData)
summary(explicitFactor1.model)
```

```{r explicit factor 2}
explicitFactor2.model <- lm(explicitFactor2 ~ implicitFactor1 + 
                              implicitFactor2 +
                              temporalContingency_left +
                              reaching_head +
                              sensoryAttenuation_neg + 
                              temporalContingency_looking +
                              sensoryAttenuation_pos +
                              temporalContingency_right,
                            data = selfData)
summary(explicitFactor2.model)
```

```{r body obstacle}
bodyObstacle.model <- lm(bodyObstacle_errorFree ~ implicitFactor1 + 
                              implicitFactor2 +
                              temporalContingency_left +
                              reaching_head +
                              sensoryAttenuation_neg + 
                              temporalContingency_looking +
                              sensoryAttenuation_pos +
                              temporalContingency_right,
                            data = selfData)
summary(bodyObstacle.model)
```

```{r body size toys}
bodySizeToys.model <- lm(bodySizeToys_errorFree ~ implicitFactor1 + 
                              implicitFactor2 +
                              temporalContingency_left +
                              reaching_head +
                              sensoryAttenuation_neg + 
                              temporalContingency_looking +
                              sensoryAttenuation_pos +
                              temporalContingency_right,
                            data = selfData)
summary(bodySizeToys.model)
```
