---
title: "2_AnalyzeData"
author: "Nina-Alisa Kollakowski"
date: "`r Sys.Date()`"
output: html_document
---

## Initializing
```{r}
set.seed(350)
library(dplyr)
library(mice)
library(psych)
library(lavaan)

nImputations <- 500
```

## Defining measures

```{r}
##defining measures
implicitSelfMeasures <- c("spatialContingency_looking", 
                          "spatialContingency_legs", 
                          "temporalContingency_looking",
                          "temporalContingency_left",
                          "temporalContingency_right",
                          "reaching_arm",
                          "reaching_head",
                          "sensoryAttenuation_pos",
                          "sensoryAttenuation_neg")
explicitSelfMeasures <- c("mirrorSelfRecognition", 
                          "videoSelfRecognition", 
                          "bodySizeDoor_errorFree",
                          "bodySizeToys_errorFree", 
                          "bodyObstacle_errorFree", 
                          "selfUnderstanding_passed", 
                          "placing_correct")
continuousVariables <- c("spatialContingency_looking", 
                         "spatialContingency_legs", 
                         "temporalContingency_looking",
                         "temporalContingency_left",
                         "temporalContingency_right",
                         "reaching_arm",
                         "reaching_head",
                         "sensoryAttenuation_pos",
                         "sensoryAttenuation_neg",
                         "bodySizeToys_errorFree", 
                         "bodyObstacle_errorFree", 
                         "selfUnderstanding_passed", 
                         "placing_correct",
                         "frakis_vocabulary")
dichotomousVariables <- c("mirrorSelfRecognition", 
                          "videoSelfRecognition", 
                          "bodySizeDoor_errorFree")
demographicVariables_numeric <- c("education_mother",
                                  "education_father",
                                  "Age_Mother",
                                  "Age_Father",
                                  "age_T1_spatialContingency",
                                  "age_T1_temporalContingency",
                                  "age_T2_reaching",
                                  "age_sensoryAttenuation",
                                  "age_T3")
demographicVariables_factor <- c("Marital_Status_num",
                                 "Siblings_num",
                                 "Primary_Language_Child_num",
                                 "Primary_Caretaker_num",
                                 "sex")
```

##load dataset
```{r}
load("joinedSelfData.RData")
currentData <- selfData
rm(selfData)
nObservations = nrow(currentData)
```

## Define correct variable types
For imputation to choose correct method for imputation, dichotomous variables need to be defined as factor
```{r}
currentData[dichotomousVariables] <- lapply(currentData[dichotomousVariables], factor)
```

## Compare demographic information of children who contributed more or less data
```{r prepare}
#add information on how much data was contributed by each child
#T1_only: only contributed to T1 (therefore other age variables empty)
#T1_and_T2: contributed data to T1 and T2 (therefore T3 age variable empty)
#allTimepoints: contributed data to all time points
demographics <- currentData %>% 
  mutate(time = ifelse(is.na(age_T2_reaching) & is.na(age_T3), "T1_only", 
                       ifelse(!is.na(age_T2_reaching) & is.na(age_T3), "T1_and_T2", 
                              "allTimepoints")))

demographics$time <- as.factor(demographics$time)

#summarise numeric demographic variables
demographics %>%
  group_by(time) %>%
  summarise(across(all_of(demographicVariables_numeric),  ~ mean(.x, na.rm = TRUE)),
            n = n())
```

```{r maternal education}
# = the higher the number, the more education in school and tertiary education) -> no significant differences
model.edu_mother_T1 <- demographics %>%
  filter(time != "T1_and_T2") %>%
  glm(time ~ education_mother, family = "binomial", data = .)
summary(model.edu_mother_T1)

model.edu_mother_T1T2 <- demographics %>%
  filter(time != "T1_only") %>%
  glm(time ~ education_mother, family = "binomial", data = .)
summary(model.edu_mother_T1T2)
```

```{r paternal education}
#(= the higher the number, the more education in school and tertiary education) -> no significant differences
model.edu_father_T1 <- demographics %>%
  filter(time != "T1_and_T2") %>%
  glm(time ~ education_father, family = "binomial", data = .)
summary(model.edu_father_T1)

model.edu_father_T1T2 <- demographics %>%
  filter(time != "T1_only") %>%
  glm(time ~ education_father, family = "binomial", data = .)
summary(model.edu_father_T1T2)
```

```{r maternal age}
#age of mother at T1 -> no significant differences
model.age_mother_T1 <- demographics %>%
  filter(time != "T1_and_T2") %>%
  glm(time ~ Age_Mother, family = "binomial", data = .)
summary(model.age_mother_T1)

model.age_mother_T1T2 <- demographics %>%
  filter(time != "T1_only") %>%
  glm(time ~ Age_Mother, family = "binomial", data = .)
summary(model.age_mother_T1T2)
```

```{r paternal age}
#age of father at T1 -> no significant differences
model.age_father_T1 <- demographics %>%
  filter(time != "T1_and_T2") %>%
  glm(time ~ Age_Father, family = "binomial", data = .)
summary(model.age_father_T1)

model.age_father_T1T2 <- demographics %>%
  filter(time != "T1_only") %>%
  glm(time ~ Age_Father, family = "binomial", data = .)
summary(model.age_father_T1T2)
```

```{r child age}
#age of child at T1 (as only this information is available for all children) -> no significant differences
model.age_child_T1 <- demographics %>%
  filter(time != "T1_and_T2") %>%
  glm(time ~ age_T1_spatialContingency, family = "binomial", data = .)
summary(model.age_child_T1)

model.age_child_T1T2 <- demographics %>%
  filter(time != "T1_only") %>%
  glm(time ~ age_T1_spatialContingency, family = "binomial", data = .)
summary(model.age_child_T1T2)
```

```{r marital status}
# (0 = unmarried, 1 = married, 2 = divorced, 3 = widowed) -> not significant
demo_marital_status <- table(demographics$Marital_Status_num, demographics$time)
fisher.test(demo_marital_status) #using fisher's test as Chi-Square claims that approximation might be incorrect
```

```{r siblings}
# (0 = no siblings, 1 = at least one sibling) -> not significant
demo_siblings <- table(demographics$Siblings_num, demographics$time)
fisher.test(demo_siblings)
```

```{r language}
#primary language of child (1 = german, 0 = other) -> not significant
demo_language <- table(demographics$Primary_Language_Child_num, demographics$time)
fisher.test(demo_language)
```

```{r caretaker}
#primary caretaker at T1 (0 = mother, 1 = father, 2 = both) -> not significant
demo_caretaker <- table(demographics$Primary_Caretaker_num, demographics$time)
fisher.test(demo_caretaker)
```

```{r sex}
#sex of child (m = male, w = female) -> significant
demo_sex <- table(demographics$sex, demographics$time)
fisher.test(demo_sex)
#more male children contributed data only to T1 (9/1), or to T1 and T2 (7/2) than contributed data to all time points (49/51)
```

##check for systematic missingness in data
conduct Little's MCAR test to confirm that data is missing at random
```{r}
#exclude demographic data here because with them in the model correlation of variables is too high to perform the test
naniar::mcar_test(currentData %>%
                    select(-all_of(demographicVariables_numeric),
                           -all_of(demographicVariables_factor))) # p = .084 -> data is missing at random
```


##scale dataset
without scaling CFA was giving the warnings that "some observed variances are (at least) a factor 1000 times larger than others; use varTable(fit) to investigate"
```{r}
currentData_scaled <- currentData %>%
  select(-id) %>% #exclude id (throws errors otherwise)
  mutate_at(continuousVariables, 
            ~(scale(.) %>% as.vector))
```


## impute Data
if data is defined as factor or numerical, mice package will automatically select the correct imputation method for each variable type:
(extract from mice help: By default, the method uses pmm, predictive mean matching (numeric data) logreg, logistic regression imputation (binary data, factor with 2 levels) polyreg, polytomous regression imputation for unordered categorical data (factor > 2 levels) polr, proportional odds model for (ordered, > 2 levels).)
```{r}
#impute 500 different datasets and set seed to make reproducible
#try imputation without demographic data to see if EFA works

currentData_scaled_woDemo <- currentData_scaled %>%
  select(-all_of(demographicVariables_factor),
         -all_of(demographicVariables_numeric))

imputedData <- mice(currentData_scaled_woDemo, #currentData_scaled, 
                    m = nImputations,
                    print = FALSE, 
                    seed = 350)

save(imputedData, file = "imputedData.Rdata")
```

## load imputed dataset
```{r}
load("imputedData.Rdata")
```

## compute correlation matrix for implicit/explicit measures for each imputed dataset
use psych::mixedCor for this
```{r echo=FALSE}
#initialize lists of correlations and standard deviations
correlationData_implicit <- vector("list", nImputations)
correlationData_explicit <- vector("list", nImputations)
standardDeviations_implicit <- vector("list", nImputations)
standardDeviations_explicit <- vector("list", nImputations)

for (i in 1:nImputations){
  #extract current imputed dataset
  curDataset <- complete(imputedData, action = i)
  
  #define factor variables back to numeric as otherwise correlation function does not work
  curDataset[dichotomousVariables] <- lapply(curDataset[dichotomousVariables], as.numeric)
  
  #compute standard deviations of measures as a matrix as needed for covariance matrix
  standardDeviations_implicit[[i]] <- diag(sapply(curDataset %>%
                                                    select(all_of(implicitSelfMeasures)),
                                                  sd)) #implicit
  
  standardDeviations_explicit[[i]] <- diag(sapply(curDataset %>%
                                                    select(all_of(explicitSelfMeasures)), 
                                                  sd)) #explicit
  
  #calculate correlations of implicit measures    
  correlationData_implicit[[i]] <- mixedCor(curDataset %>%
                                              select(all_of(implicitSelfMeasures)),
                                            c = intersect(implicitSelfMeasures, continuousVariables),
                                            d = intersect(implicitSelfMeasures, dichotomousVariables))$rho 
  
  #calculate correlations of explicit measures
  correlationData_explicit[[i]] <- mixedCor(curDataset %>%
                                              select(all_of(explicitSelfMeasures)),
                                            c = intersect(explicitSelfMeasures, continuousVariables),
                                            d = intersect(explicitSelfMeasures, dichotomousVariables))$rho 
}
rm(curDataset)
```

## create covariance matrix from each correlation matrix
```{r}
#initialize lists of covariances
covarianceData_implicit <- vector("list", nImputations)
covarianceData_explicit <- vector("list", nImputations)

for (i in 1:nImputations){
  covarianceData_implicit[[i]] <- standardDeviations_implicit[[i]] %*% correlationData_implicit[[i]] %*% standardDeviations_implicit[[i]]
  
  covarianceData_explicit[[i]] <- standardDeviations_explicit[[i]] %*% correlationData_explicit[[i]] %*% standardDeviations_explicit[[i]]
}
```

## create average matrices for implicit/explicit measures
```{r}
covariance_implicit <- apply(simplify2array(covarianceData_implicit), c(1,2), mean)
rownames(covariance_implicit) <- implicitSelfMeasures
colnames(covariance_implicit) <- implicitSelfMeasures

covariance_explicit <- apply(simplify2array(covarianceData_explicit), c(1,2), mean)
rownames(covariance_explicit) <- explicitSelfMeasures
colnames(covariance_explicit) <- explicitSelfMeasures

correlation_implicit <- apply(simplify2array(correlationData_implicit), c(1,2), mean)
rownames(correlation_implicit) <- implicitSelfMeasures
colnames(correlation_implicit) <- implicitSelfMeasures

correlation_explicit <- apply(simplify2array(correlationData_explicit), c(1,2), mean)
rownames(correlation_explicit) <- explicitSelfMeasures
colnames(correlation_explicit) <- explicitSelfMeasures

```


## compute CFA of implicit/explicit measures
MLR estimator -> not possible because computing it with covariance matrix only
evaluate fit using X2-test, RMSEA, SRMR, CFI
good fit if 3/4 indicators suggest good fit
X2 = non-significant
RMSEA < .08
SRMR <.11
CFI >.95
```{r CFA implicit}
implicitCFA.model <- "implicit =~ spatialContingency_looking + 
                                  spatialContingency_legs + 
                                  temporalContingency_looking + 
                                  temporalContingency_left + 
                                  temporalContingency_right + 
                                  reaching_arm + 
                                  reaching_head + 
                                  sensoryAttenuation_pos + 
                                  sensoryAttenuation_neg"

implicitCFA <- cfa(implicitCFA.model, 
                   sample.cov = covariance_implicit, 
                   sample.nobs = nObservations,
                   estimator = "ML")

summary(implicitCFA)
fitMeasures(implicitCFA, fit.measures = c("rmsea", "srmr", "cfi"))
```
significant X2-test (p = 0.000) -> bad
RMSEA > .08 (0.132) -> bad
SRMR > .11 (0.107) -> bad
CFI < .95 (0.370) -> bad
all indicators show bad fit of CFA for implicit measures -> perform EFA

```{r CFA explicit}
explicitCFA.model <- 'explicit =~ mirrorSelfRecognition + 
                                  videoSelfRecognition + 
                                  bodySizeDoor_errorFree + 
                                  bodySizeToys_errorFree +
                                  bodyObstacle_errorFree + 
                                  selfUnderstanding_passed +
                                  placing_correct'
explicitCFA <- cfa(explicitCFA.model, sample.cov = covariance_explicit, sample.nobs = nObservations) 
summary(explicitCFA)
fitMeasures(explicitCFA, fit.measures = c("rmsea", "srmr", "cfi"))
```
significant X2-test (p = 0.004) -> bad
RMSEA > .08 (0.105) -> bad
SRMR < .11 (0.083) -> good
CFI < .95 (0.648) -> bad
3/4 indicators show bad fit of CFA for explicit measures -> perform EFA

##perform EFA for implicit measures
1) Bartlett's test to check if correlation matrix different from identity matrix (needs to be significant)
```{r Bartlett implicit}
<<<<<<< HEAD
cortest.bartlett(correlation_implicit, n = nObservations)
```
test is significant -> proceed
2) KMO >=.5, otherwise exclude variables with smallest KMO until criterion is reached
```{r KMO implicit 1}
KMO(correlation_implicit)

#define correlation matrix for later analysis
cur_correlation_implicit <- correlation_implicit
```

KMO = 0.46, exclude temporalContingency_left (0.41)

```{r KMO implicit 2}
#update correlation matrix without excluded variable
cur_correlation_implicit <- cur_correlation_implicit[!rownames(cur_correlation_implicit) == "temporalContingency_left",
                                              !colnames(cur_correlation_implicit) == "temporalContingency_left"]
#list excluded variables
excludedVariables_implicit_KMO <- list("temporalContingency_left")

#run KMO again
KMO(cur_correlation_implicit)
=======
cortest.bartlett(correlation_implicit, n = nObservations) #significant -> proceed
```

2) KMO >=.5, otherwise exclude variables with smallest KMO until criterion is reached
as EFA produces Heywood cases, trying to exclude all variables with KMO <.5 iteratively
```{r KMO implicit 1}
KMO(correlation_implicit) #KMO = 0.44, exclude sensoryAttenuation_neg  (0.35)

cur_correlation_implicit <- correlation_implicit
```
```{r KMO implicit 2}
correlation_implicit1 <- correlation_implicit[!rownames(correlation_implicit) == "sensoryAttenuation_neg",
                                              !colnames(correlation_implicit) == "sensoryAttenuation_neg"]
excludedVariables_implicit_KMO <- list("sensoryAttenuation_neg")
excludedVariables_implicit <- list("sensoryAttenuation_neg")

#run KMO again
KMO(correlation_implicit1) #KMO = 0.48 -> exclude reaching_head (0.38)

cur_correlation_implicit <- correlation_implicit1
```
```{r KMO implicit 3}
correlation_implicit2 <- correlation_implicit1[!rownames(correlation_implicit1) == "reaching_head",
                                               !colnames(correlation_implicit1) == "reaching_head"]
excludedVariables_implicit_KMO <- append(excludedVariables_implicit_KMO, "reaching_head")
excludedVariables_implicit <- append(excludedVariables_implicit, "reaching_head")

#run KMO again
KMO(correlation_implicit2) #KMO = 0.51, exclude reaching_arm (0.45)

cur_correlation_implicit <- correlation_implicit2
```
```{r KMO implicit 4}
correlation_implicit3 <- correlation_implicit2[!rownames(correlation_implicit2) == "reaching_arm",
                                               !colnames(correlation_implicit2) == "reaching_arm"]
excludedVariables_implicit_KMO <- append(excludedVariables_implicit_KMO, "reaching_arm")
excludedVariables_implicit <- append(excludedVariables_implicit, "reaching_arm")

#run KMO again
KMO(correlation_implicit3) #KMO = 0.52, exclude temporalContingency_left (0.44)

cur_correlation_implicit <- correlation_implicit3
>>>>>>> e33e061fd96f72ce14759acee9fb3df9e5f62544
```
```{r KMO implicit 5}
correlation_implicit4 <- correlation_implicit3[!rownames(correlation_implicit3) == "temporalContingency_left",
                                               !colnames(correlation_implicit3) == "temporalContingency_left"]
excludedVariables_implicit_KMO <- append(excludedVariables_implicit_KMO, "temporalContingency_left")
excludedVariables_implicit <- append(excludedVariables_implicit, "temporalContingency_left")

<<<<<<< HEAD
KMO = 0.51
however, when proceeding from here, parallel analysis suggests 4 factors and EFA produces Heywood cases
therefore now excluding variable with smallest KMO until all variables have KMO >= 0.5
first, exclude reaching_head (0.43)

```{r KMO implicit 3}
#update correlation matrix without excluded variable
cur_correlation_implicit <- cur_correlation_implicit[!rownames(cur_correlation_implicit) == "reaching_head",
                                              !colnames(cur_correlation_implicit) == "reaching_head"]

#list excluded variables
excludedVariables_implicit_KMO <- append(excludedVariables_implicit_KMO, "reaching_head")

#run KMO again
KMO(cur_correlation_implicit)
```

overall KMO = 0.55, but still variables < 0.5
exclude sensoryAttenuation_neg (0.42)

```{r KMO implicit 4}
#update correlation matrix without excluded variable
cur_correlation_implicit <- cur_correlation_implicit[!rownames(cur_correlation_implicit) == "sensoryAttenuation_neg",
                                              !colnames(cur_correlation_implicit) == "sensoryAttenuation_neg"]

#list excluded variables
excludedVariables_implicit_KMO <- append(excludedVariables_implicit_KMO, "sensoryAttenuation_neg")

#run KMO again
KMO(cur_correlation_implicit)
```

overall KMO = 0.59 & all variables > 0.5 -> proceed

=======
#run KMO again
KMO(correlation_implicit4)

cur_correlation_implicit <- correlation_implicit4
```
>>>>>>> e33e061fd96f72ce14759acee9fb3df9e5f62544
3) parallel analysis with reduced correlation matrix to decide number of factors

```{r parallel analysis implicit}
fa.parallel(cur_correlation_implicit, n.obs = nObservations, n.iter = 1000, fm = "ml", fa = "fa")
```
<<<<<<< HEAD
parallel analysis suggests 2 factors

4) run EFA with principal axis factoring with oblique (direct oblimin) rotation
```{r EFA implicit}
#run EFA with 2 factors as suggested by parallel analysis
=======
parallel analysis suggests 2 factors      

4) run EFA with principal axis factoring with oblique (direct oblimin) rotation
```{r EFA implicit}
#run EFA with 3 factors as suggested by parallel analysis
>>>>>>> e33e061fd96f72ce14759acee9fb3df9e5f62544
efa.implicit <- fa(cur_correlation_implicit, nfactors = 2, n.obs = nObservations, 
                   rotate = 'oblimin', fm = 'pa', max.iter = 1000)

#print results: cut-off of .4 as only loadings with >=.4 will be assigned to this factor
print.psych(efa.implicit, digits=3, sort=TRUE)

```
5) average imputed datasets for implicit variable scores
```{r implicit scores}
variables_implicit <- vector("list", nImputations)

<<<<<<< HEAD
5) assign variables to factors with loadings of >=.4
```{r assign variables to implicit factors}
#exclude variables that don't load on any factor with loading of >=.4
excludedVariables_implicit <- append(excludedVariables_implicit_KMO, c("temporalContingency_looking",
                                                                   "sensoryAttenuation_pos",
                                                                   "temporalContingency_right"))

#extract factor loading from EFA
relevantFactorLoadings_implicit <- efa.implicit$loadings

#replace loadings < 0.4 with 0 for correct calculation of factor scores
relevantFactorLoadings_implicit[abs(relevantFactorLoadings_implicit) < 0.4] <- 0
```

6) calculate factor scores
```{r implicit factor scores}
#initialize lists for factor scores and all excluded variables
factorScores_implicit <- vector("list", nImputations)
otherVariables_implicit <- vector("list", nImputations)

#calculate factor scores and scores for excluded variables for each imputed dataset
=======
#average imputed datasets for variable scores
>>>>>>> e33e061fd96f72ce14759acee9fb3df9e5f62544
for (i in 1:nImputations){
  curDataset <- complete(imputedData, action = i)
  
  variables_implicit[[i]] <- data.matrix(curDataset %>%
                                           select(all_of(implicitSelfMeasures)))
}

implicitSelf <- data.frame(apply(simplify2array(variables_implicit), c(1,2), mean))
implicitSelf <- mutate(implicitSelf, id = 1:nObservations)
```


## perform EFA for explicit measures
1) Bartlett's test to check if correlation matrix different from identity matrix (needs to be significant)
```{r Bartlett explicit}
<<<<<<< HEAD
cortest.bartlett(correlation_explicit, n = nObservations)
=======
cortest.bartlett(correlation_explicit, n = nObservations) #significant -> proceed
>>>>>>> e33e061fd96f72ce14759acee9fb3df9e5f62544
```
test is significant -> proceed
2) KMO >.5, otherwise exclude variables with smallest KMO until criterion is reached
<<<<<<< HEAD
```{r KMO explicit 1}
KMO(correlation_explicit)
cur_correlation_explicit <- correlation_explicit
```
KMO = 0.52, 
however, when proceeding from here, parallel analysis suggests 4 factors and EFA produces Heywood cases
therefore now excluding variable with smallest KMO until all variables have KMO >= 0.5
first, exclude bodyObstacle_errorFree (0.34)

```{r KMO explicit 2}
#update correlation matrix without excluded variable
cur_correlation_explicit <- cur_correlation_explicit[!rownames(cur_correlation_explicit) == "bodyObstacle_errorFree",
                                              !colnames(cur_correlation_explicit) == "bodyObstacle_errorFree"]

#list excluded variables
excludedVariables_explicit_KMO <- list("bodyObstacle_errorFree")

#run KMO again
KMO(correlation_explicit1)
```

KMO = 0.54, but still one variable <.5 
excluding bodySizeToys_errorFree (0.36)

```{r KMO explicit 3}
#update correlation matrix without excluded variable
cur_correlation_explicit <- cur_correlation_explicit[!rownames(cur_correlation_explicit) == "bodySizeToys_errorFree",
                                              !colnames(cur_correlation_explicit) == "bodySizeToys_errorFree"]

#list excluded variables
excludedVariables_explicit_KMO <- append(excludedVariables_explicit_KMO, "bodySizeToys_errorFree")

#run KMO again
KMO(cur_correlation_explicit)
```
KMO = 0.65 & all variables >0.5 -> proceed

=======
as EFA produces Heywood cases, trying to exclude all variables with KMO <.5 iteratively
```{r KMO explicit 1}
KMO(correlation_explicit) #KMO = 0.54, excluding bodyObstacle_errorFree (0.34)

cur_correlation_explicit <- correlation_explicit
```
```{r KMO explicit 2}
correlation_explicit1 <- correlation_explicit[!rownames(correlation_explicit) == "bodyObstacle_errorFree",
                                              !colnames(correlation_explicit) == "bodyObstacle_errorFree"]
excludedVariables_explicit_KMO <- list("bodyObstacle_errorFree")
excludedVariables_explicit <- list("bodyObstacle_errorFree")

#run KMO again
KMO(correlation_explicit1) #KMO = 0.55, but variables <.5 -> excluding bodySizeToys_errorFree (0.40)

cur_correlation_explicit <- correlation_explicit1
```
```{r KMO explicit 3}
correlation_explicit2 <- correlation_explicit1[!rownames(correlation_explicit1) == "bodySizeToys_errorFree",
                                               !colnames(correlation_explicit1) == "bodySizeToys_errorFree"]
excludedVariables_explicit_KMO <- append(excludedVariables_explicit_KMO, "bodySizeToys_errorFree")
excludedVariables_explicit <- append(excludedVariables_explicit, "bodySizeToys_errorFree")

#run KMO again
KMO(correlation_explicit2) #KMO = 0.65, all variables >0.5 -> proceed

cur_correlation_explicit <- correlation_explicit2
```
>>>>>>> e33e061fd96f72ce14759acee9fb3df9e5f62544
3) parallel analysis with reduced correlation matrix to decide number of factors

```{r parallel analysis explicit}
fa.parallel(cur_correlation_explicit, n.obs = nObservations, n.iter = 1000, fm = "ml", fa = "fa")
```
parallel analysis suggests 2 factors

4) run EFA with principal axis factoring with oblique (direct oblimin) rotation
```{r EFA explicit}
<<<<<<< HEAD
#run EFA with 2 factors as suggested by parallel analysis
=======
#run EFA with 3 factors as suggested by parallel analysis
>>>>>>> e33e061fd96f72ce14759acee9fb3df9e5f62544
efa.explicit <- fa(cur_correlation_explicit, nfactors = 2, n.obs = nObservations, 
                   rotate = 'oblimin', fm = 'pa', max.iter = 1000)

#print results: cut-off of .4 as only loadings with >=.4 will be assigned to this factor
print.psych(efa.explicit, digits=2, sort=TRUE) 

```

<<<<<<< HEAD
5) assign variables to factors with loadings of >=.4
```{r assign to explicit factors}
=======
5) assign variables to factors with loadings of >=.39
```{r assign to explicit factors}
#exclude variables that don't load on any factor with loading of >=.4
excludedVariables_explicit <- append(excludedVariables_explicit, "videoSelfRecognition")

>>>>>>> e33e061fd96f72ce14759acee9fb3df9e5f62544
#extract factor loading from EFA
relevantFactorLoadings_explicit <- efa.explicit$loadings

#replace loadings < .39 with 0 for correct calculation of factor scores
relevantFactorLoadings_explicit[abs(relevantFactorLoadings_explicit) < 0.39] <- 0
```

6) calculate factor scores
```{r explicit factor scores}
#initialize lists for factor scores and all excluded variables
factorScores_explicit <- vector("list", nImputations)
otherVariables_explicit <- vector("list", nImputations)

#calculate factor scores and scores for excluded variables for each imputed dataset
for (i in 1:nImputations){
  curDataset <- complete(imputedData, action = i)
  
  #define factor variables back to numeric to be able to compute means
  curDataset[dichotomousVariables] <- lapply(curDataset[dichotomousVariables], as.numeric)
  
  factorScore_buffer <- curDataset %>%
    select(all_of(setdiff(explicitSelfMeasures, excludedVariables_explicit_KMO))) %>%
    factor.scores(x = ., relevantFactorLoadings_explicit)
  
  factorScores_explicit[[i]] <- factorScore_buffer$scores
  
  otherVariables_explicit[[i]] <- data.matrix(curDataset %>%
                                                select(all_of(simplify2array(excludedVariables_explicit_KMO))))
}
rm(factorScore_buffer)
rm(curDataset)

#create average factor scores and excluded variable scores for all datasets
factorScores_explicit_avg <- apply(simplify2array(factorScores_explicit), c(1,2), mean)
otherVariables_explicit_avg <- apply(simplify2array(otherVariables_explicit), c(1,2), mean)

#combine factor scores and scores for excluded variables into dataframe for explicit self
explicitSelf <- cbind(as.data.frame(factorScores_explicit_avg), as.data.frame(otherVariables_explicit_avg))
explicitSelf <- explicitSelf %>%
  rename(explicitFactor1 = PA1,
         explicitFactor2 = PA2) %>%
  mutate(id = 1:nObservations)

#make dichotomous variables dichotomous as through averaging values are wrong
explicitSelf <- explicitSelf %>%
  mutate(videoSelfRecognition = videoSelfRecognition - 1) %>% #subtract one, as R turns factors into 1 and 2 values
  mutate(videoSelfRecognition = ifelse(videoSelfRecognition < 0.5, 0, 1))
```


## linear regressions of implicit -> explicit self
run regressions of each explicit factor/variable with all implicit variables as predictors
```{r prepare dataframe}
#merge implicit and explicit dataset
selfData <- merge(implicitSelf, explicitSelf, by = "id")
```

```{r explicit factor 1}
<<<<<<< HEAD
explicitFactor1.model <- lm(explicitFactor1 ~ implicitFactor1 + 
                              implicitFactor2 +
                              temporalContingency_left +
                              reaching_head +
                              sensoryAttenuation_neg + 
                              temporalContingency_looking +
                              sensoryAttenuation_pos +
                              temporalContingency_right, 
=======
explicitFactor1.model <- lm(explicitFactor1 ~ spatialContingency_looking + 
                              spatialContingency_legs +
                              temporalContingency_looking +
                              temporalContingency_left +
                              temporalContingency_right +
                              reaching_arm +
                              reaching_head +
                              sensoryAttenuation_pos +
                              sensoryAttenuation_neg, 
>>>>>>> e33e061fd96f72ce14759acee9fb3df9e5f62544
                            data = selfData)
summary(explicitFactor1.model)
confint(explicitFactor1.model)
```

```{r explicit factor 2}
<<<<<<< HEAD
explicitFactor2.model <- lm(explicitFactor2 ~ implicitFactor1 + 
                              implicitFactor2 +
                              temporalContingency_left +
                              reaching_head +
                              sensoryAttenuation_neg + 
                              temporalContingency_looking +
                              sensoryAttenuation_pos +
                              temporalContingency_right,
=======
explicitFactor2.model <- lm(explicitFactor2 ~ spatialContingency_looking + 
                              spatialContingency_legs +
                              temporalContingency_looking +
                              temporalContingency_left +
                              temporalContingency_right +
                              reaching_arm +
                              reaching_head +
                              sensoryAttenuation_pos +
                              sensoryAttenuation_neg, 
>>>>>>> e33e061fd96f72ce14759acee9fb3df9e5f62544
                            data = selfData)
summary(explicitFactor2.model)
confint(explicitFactor2.model)
```
```{r body obstacle}
<<<<<<< HEAD
bodyObstacle.model <- lm(bodyObstacle_errorFree ~ implicitFactor1 + 
                              implicitFactor2 +
                              temporalContingency_left +
                              reaching_head +
                              sensoryAttenuation_neg + 
                              temporalContingency_looking +
                              sensoryAttenuation_pos +
                              temporalContingency_right,
                            data = selfData)
=======
bodyObstacle.model <- lm(bodyObstacle_errorFree ~ spatialContingency_looking + 
                           spatialContingency_legs +
                           temporalContingency_looking +
                           temporalContingency_left +
                           temporalContingency_right +
                           reaching_arm +
                           reaching_head +
                           sensoryAttenuation_pos +
                           sensoryAttenuation_neg, 
                         data = selfData)
>>>>>>> e33e061fd96f72ce14759acee9fb3df9e5f62544
summary(bodyObstacle.model)
confint(bodyObstacle.model)
```

```{r body size toys}
<<<<<<< HEAD
bodySizeToys.model <- lm(bodySizeToys_errorFree ~ implicitFactor1 + 
                              implicitFactor2 +
                              temporalContingency_left +
                              reaching_head +
                              sensoryAttenuation_neg + 
                              temporalContingency_looking +
                              sensoryAttenuation_pos +
                              temporalContingency_right,
                            data = selfData)
=======
bodySizeToys.model <- lm(bodySizeToys_errorFree ~ spatialContingency_looking + 
                           spatialContingency_legs +
                           temporalContingency_looking +
                           temporalContingency_left +
                           temporalContingency_right +
                           reaching_arm +
                           reaching_head +
                           sensoryAttenuation_pos +
                           sensoryAttenuation_neg, 
                         data = selfData)
>>>>>>> e33e061fd96f72ce14759acee9fb3df9e5f62544
summary(bodySizeToys.model)
confint(bodySizeToys.model)
```
```{r video-self recognition}
videoSelfRecognition.model <- glm(videoSelfRecognition ~ spatialContingency_looking + 
                                    spatialContingency_legs +
                                    temporalContingency_looking +
                                    temporalContingency_left +
                                    temporalContingency_right +
                                    reaching_arm +
                                    reaching_head +
                                    sensoryAttenuation_pos +
                                    sensoryAttenuation_neg, 
                                  data = selfData,
                                  family = "binomial")
summary(videoSelfRecognition.model)
confint(videoSelfRecognition.model)
```

##linear regressions controlled for language
```{r prepare dataframe with language}
language_scores <- vector("list", nImputations)

#average imputed datasets for variable scores
for (i in 1:nImputations){
  curDataset <- complete(imputedData, action = i)
  
  language_scores[[i]] <- data.matrix(curDataset %>%
                                        select(frakis_vocabulary))
}

languageData <- data.frame(apply(simplify2array(language_scores), c(1,2), mean))
languageData <- mutate(languageData, id = 1:nObservations)

selfData_language <- merge(languageData,
                           merge(implicitSelf, explicitSelf, by = "id"),
                           by = "id")
```

```{r explicit factor 1 (controlled)}
explicitFactor1_lang.model <- lm(explicitFactor1 ~ spatialContingency_looking + 
                                   spatialContingency_legs +
                                   temporalContingency_looking +
                                   temporalContingency_left +
                                   temporalContingency_right +
                                   reaching_arm +
                                   reaching_head +
                                   sensoryAttenuation_pos +
                                   sensoryAttenuation_neg +
                                   frakis_vocabulary, 
                                 data = selfData_language)
summary(explicitFactor1_lang.model)
confint(explicitFactor1_lang.model)
```

```{r explicit factor 2 (controlled)}
explicitFactor2_lang.model <- lm(explicitFactor2 ~ spatialContingency_looking + 
                                   spatialContingency_legs +
                                   temporalContingency_looking +
                                   temporalContingency_left +
                                   temporalContingency_right +
                                   reaching_arm +
                                   reaching_head +
                                   sensoryAttenuation_pos +
                                   sensoryAttenuation_neg +
                                   frakis_vocabulary, 
                                 data = selfData_language)
summary(explicitFactor2_lang.model)
confint(explicitFactor2_lang.model)
```
```{r body obstacle (controlled)}
bodyObstacle_lang.model <- lm(bodyObstacle_errorFree ~ spatialContingency_looking + 
                                spatialContingency_legs +
                                temporalContingency_looking +
                                temporalContingency_left +
                                temporalContingency_right +
                                reaching_arm +
                                reaching_head +
                                sensoryAttenuation_pos +
                                sensoryAttenuation_neg +
                                frakis_vocabulary, 
                              data = selfData_language)
summary(bodyObstacle_lang.model)
confint(bodyObstacle_lang.model)
```

```{r body size toys (controlled)}
bodySizeToys_lang.model <- lm(bodySizeToys_errorFree ~ spatialContingency_looking + 
                                spatialContingency_legs +
                                temporalContingency_looking +
                                temporalContingency_left +
                                temporalContingency_right +
                                reaching_arm +
                                reaching_head +
                                sensoryAttenuation_pos +
                                sensoryAttenuation_neg +
                                frakis_vocabulary, 
                              data = selfData_language)
summary(bodySizeToys_lang.model)
confint(bodySizeToys_lang.model)
```

```{r video-self recognition (controlled)}
videoSelfRecognition.model <- glm(videoSelfRecognition ~ spatialContingency_looking + 
                                    spatialContingency_legs +
                                    temporalContingency_looking +
                                    temporalContingency_left +
                                    temporalContingency_right +
                                    reaching_arm +
                                    reaching_head +
                                    sensoryAttenuation_pos +
                                    sensoryAttenuation_neg +
                                    frakis_vocabulary, 
                                  data = selfData_language,
                                  family = "binomial")
summary(videoSelfRecognition.model)
confint(videoSelfRecognition.model)
```